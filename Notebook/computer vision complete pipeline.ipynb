{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7884b083",
   "metadata": {},
   "source": [
    "üéØ Computer Vision Project - Complete Pipeline\n",
    "\n",
    "## üìã Table of Contents\n",
    "1. [Project Overview](#Project-overview)\n",
    "2. [SETUP & IMPORTS](#SETUP-&-IMPORTS)\n",
    "3. [Data Engineering Pipeline](#data-engineering-pipeline)\n",
    "4. [Exploratory Data Analysis](#Exploratory-data-analysis)\n",
    "5. [Model Building & Training](#Model-building--training)\n",
    "6. [Model Evaluation](Model-evaluation)\n",
    "7. [EXPERIMENT WORKFLOW](#EXPERIMENT-WORKFLOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d7e219",
   "metadata": {},
   "source": [
    "# Project Overview\n",
    "\n",
    "This notebook implements a complete computer vision pipeline for image classification using transfer learning. The pipeline includes:\n",
    "\n",
    "- üìä Data augmentation and preprocessing\n",
    "- üîç Exploratory data analysis\n",
    "- ü§ñ Multiple model training (VGG16, VGG19, InceptionV3)\n",
    "- üìà Comprehensive model evaluation\n",
    "- üìä Performance comparison and visualization\n",
    "\n",
    "**Key Features:**\n",
    "- Automated data splitting (Train/Validation/Test)\n",
    "- Multiple data augmentation techniques\n",
    "- Transfer learning \n",
    "- Comprehensive evaluation metrics\n",
    "- Production-ready pipeline structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30103da8",
   "metadata": {},
   "source": [
    "# SETUP & IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675fdefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from itertools import cycle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import Model, Input, regularizers\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from tensorflow.keras.applications import VGG16, VGG19, InceptionV3\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg16_preprocess\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input as vgg19_preprocess\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa9eece",
   "metadata": {},
   "source": [
    "# data engineering pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ffcae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_pipeline(source_dir, base_dir, image_size=(224, 224), val_ratio=0.20):\n",
    "    \"\"\"\n",
    "    Augments train & test images separately.\n",
    "    Splits only the train set into train and validation sets.\n",
    "    No duplicate augmented dataset stored ‚Äî only final train, val, and test folders.\n",
    "    Shows progress with tqdm.\n",
    "    \"\"\"\n",
    "    print(\"Starting Data Engineering Pipeline...\")\n",
    "\n",
    "    # Final directories\n",
    "    train_dir = os.path.join(base_dir, 'train')\n",
    "    validation_dir = os.path.join(base_dir, 'validation')\n",
    "    test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "    # Remove old output\n",
    "    if os.path.exists(base_dir):\n",
    "        print(f\"Removing old base directory: {base_dir}\")\n",
    "        shutil.rmtree(base_dir)\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(validation_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    def augment_images(src_dir):\n",
    "        \"\"\"Resize + rotate + flip images and return augmented images in memory.\"\"\"\n",
    "        class_labels = [d for d in os.listdir(src_dir) if os.path.isdir(os.path.join(src_dir, d))]\n",
    "        all_files = []\n",
    "        all_labels = []\n",
    "        total_original = 0\n",
    "        total_augmented = 0\n",
    "\n",
    "        print(f\"Processing directory: {src_dir}\")\n",
    "        for class_name in class_labels:\n",
    "            src_class_dir = os.path.join(src_dir, class_name)\n",
    "            files = os.listdir(src_class_dir)\n",
    "            total_original += len(files)\n",
    "\n",
    "            for filename in tqdm(files, desc=f\"Augmenting {class_name}\", unit=\"img\"):\n",
    "                img_path = os.path.join(src_class_dir, filename)\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "\n",
    "                resized = cv2.resize(img, (image_size[1], image_size[0]))\n",
    "                rotated = cv2.rotate(resized, cv2.ROTATE_90_CLOCKWISE)\n",
    "                flipped = cv2.flip(resized, 0)\n",
    "\n",
    "                base_name, ext = os.path.splitext(filename)\n",
    "                aug_set = [\n",
    "                    (f\"{base_name}_orig{ext}\", resized),\n",
    "                    (f\"{base_name}_rot{ext}\", rotated),\n",
    "                    (f\"{base_name}_flip{ext}\", flipped)\n",
    "                ]\n",
    "\n",
    "                for new_name, new_img in aug_set:\n",
    "                    all_files.append((class_name, new_name, new_img))\n",
    "                    all_labels.append(class_name)\n",
    "                    total_augmented += 1\n",
    "\n",
    "        print(f\"Original images: {total_original}\")\n",
    "        print(f\"Augmented images (including original resized): {total_augmented}\")\n",
    "        return all_files, all_labels, class_labels\n",
    "\n",
    "    # Augment TRAIN\n",
    "    print(\"\\n=== Augmenting TRAIN set ===\")\n",
    "    train_files_aug, train_labels_aug, class_labels = augment_images(os.path.join(source_dir, 'train'))\n",
    "\n",
    "    # Split augmented train into train/validation\n",
    "    print(\"\\n=== Splitting TRAIN set into train/validation ===\")\n",
    "    train_files_list, val_files_list, train_labels_list, val_labels_list = train_test_split(\n",
    "        train_files_aug, train_labels_aug,\n",
    "        test_size=val_ratio,\n",
    "        random_state=42,\n",
    "        stratify=train_labels_aug\n",
    "    )\n",
    "\n",
    "    def save_images(file_tuples, dest_dir):\n",
    "        for cls, fname, img in tqdm(file_tuples, desc=f\"Saving to {os.path.basename(dest_dir)}\", unit=\"img\"):\n",
    "            cls_dir = os.path.join(dest_dir, cls)\n",
    "            os.makedirs(cls_dir, exist_ok=True)\n",
    "            cv2.imwrite(os.path.join(cls_dir, fname), img)\n",
    "\n",
    "    # Save final TRAIN and VALIDATION sets\n",
    "    save_images(train_files_list, train_dir)\n",
    "    save_images(val_files_list, validation_dir)\n",
    "\n",
    "    # Augment TEST\n",
    "    print(\"\\n=== Augmenting TEST set ===\")\n",
    "    test_files_aug, _, _ = augment_images(os.path.join(source_dir, 'test'))\n",
    "    save_images(test_files_aug, test_dir)\n",
    "\n",
    "    # Final stats\n",
    "    print(\"\\nPipeline finished successfully.\")\n",
    "    print(f\"Final TRAIN images: {len(train_files_list)}\")\n",
    "    print(f\"Final VALIDATION images: {len(val_files_list)}\")\n",
    "    print(f\"Final TEST images: {len(test_files_aug)}\")\n",
    "\n",
    "    return {\n",
    "        'train_dir': train_dir,\n",
    "        'validation_dir': validation_dir,\n",
    "        'test_dir': test_dir,\n",
    "        'class_labels': class_labels\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c0f870",
   "metadata": {},
   "source": [
    " # Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a593b99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_dataset_distribution(dataset_dir, result_dir=None, data_type=None):\n",
    "    \"\"\"\n",
    "    Given a dataset directory containing subfolders like:\n",
    "        train/\n",
    "            class1/\n",
    "            class2/\n",
    "        test/\n",
    "            class1/\n",
    "            class2/\n",
    "        validation/ (optional)\n",
    "            class1/\n",
    "            class2/\n",
    "    \n",
    "    This function will automatically detect the splits and visualize\n",
    "    the class distribution in each subset.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataset_dir: Path to the dataset directory\n",
    "    - result_dir: Directory to save the visualization (optional)\n",
    "    - data_type: Dataset type identifier for filename (e.g., 'original', 'preprocessed') (optional)\n",
    "    \"\"\"\n",
    "    \n",
    "    def count_files(directory):\n",
    "        \"\"\"Count number of images in each class folder.\"\"\"\n",
    "        if directory is None or not os.path.isdir(directory):\n",
    "            return {}    \n",
    "        counts = {}\n",
    "        for class_name in sorted(os.listdir(directory)):\n",
    "            class_path = os.path.join(directory, class_name)\n",
    "            if os.path.isdir(class_path):\n",
    "                counts[class_name] = len(os.listdir(class_path))\n",
    "        return counts \n",
    "\n",
    "    # Detect splits\n",
    "    splits = {}\n",
    "    for split_name in [\"train\", \"test\", \"validation\", \"val\"]:\n",
    "        split_path = os.path.join(dataset_dir, split_name)\n",
    "        if os.path.isdir(split_path):\n",
    "            splits[split_name] = split_path \n",
    "\n",
    "\n",
    "    if not splits:\n",
    "        print(f\"No train/test/validation folders found inside {dataset_dir}\")\n",
    "        return\n",
    "\n",
    "    # Collect counts\n",
    "    all_classes = set()\n",
    "    data = []     \n",
    "    for split_name, split_path in splits.items():\n",
    "        counts = count_files(split_path)\n",
    "        all_classes.update(counts.keys())\n",
    "        for cls, cnt in counts.items():\n",
    "            data.append({\"Class\": cls, \"Count\": cnt, \"Set\": split_name.capitalize()})\n",
    "\n",
    "    # Fill missing classes with zero counts\n",
    "    for split_name in splits.keys():\n",
    "        for cls in all_classes:\n",
    "            if not any(d[\"Class\"] == cls and d[\"Set\"] == split_name.capitalize() for d in data):\n",
    "                data.append({\"Class\": cls, \"Count\": 0, \"Set\": split_name.capitalize()})\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    ax = sns.barplot(x=\"Class\", y=\"Count\", hue=\"Set\", data=df)\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container)\n",
    "    plt.title(\"Dataset Class Distribution by Split\")\n",
    "    plt.ylabel(\"Number of Images\")\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot if result_dir is provided\n",
    "    if result_dir is not None:\n",
    "        # Create result directory if it doesn't exist\n",
    "        os.makedirs(result_dir, exist_ok=True)\n",
    "        \n",
    "        # Generate filename components\n",
    "        splits_str = \"_\".join(sorted(splits.keys()))\n",
    "        data_type_str = f\"_{data_type}\" if data_type else \"\"\n",
    "        filename = f\"{splits_str}_distribution{data_type_str}.png\"\n",
    "        save_path = os.path.join(result_dir, filename)\n",
    "        \n",
    "        # Save the plot\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Visualization saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    #plot training history\n",
    "    \n",
    "def plot_training_history(history, model_name, save_dir):\n",
    "    \"\"\"Plot training and validation accuracy/loss and save the figure\"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title(f'Training and Validation Accuracy - {model_name}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Training and Validation Loss - {model_name}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    save_path = os.path.join(save_dir, f'training_history_{model_name}.png')\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Training history plot saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f588e759",
   "metadata": {},
   "source": [
    "# Model Building & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdadc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " # Create model configration from where we extract the model and it\n",
    "model_configs = {\n",
    "    \"vgg16\": {\n",
    "        \"model_class\": VGG16,\n",
    "        \"preprocess_fn\": vgg16_preprocess,\n",
    "        \"input_shape\": (224, 224, 3)\n",
    "    },\n",
    "    \"vgg19\": {\n",
    "        \"model_class\": VGG19,\n",
    "        \"preprocess_fn\": vgg19_preprocess,\n",
    "        \"input_shape\": (224, 224, 3)\n",
    "    },\n",
    "    \"inceptionv3\": {\n",
    "        \"model_class\": InceptionV3,\n",
    "        \"preprocess_fn\": inception_preprocess,\n",
    "        \"input_shape\": (299, 299, 3)  # Inception requires larger input\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def setup_datagenerator(train_dir, val_dir, test_dir, preprocess_fn, batch_size=16, image_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Create and configure data generators for the model.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_dir: Path to training data directory\n",
    "    - val_dir: Path to validation data directory\n",
    "    - test_dir: Path to test data directory\n",
    "    - preprocess_fn: Preprocessing function to apply to images\n",
    "    - batch_size: Batch size for generators (default: 32)\n",
    "    - image_size: Target image size as (height, width) (default: (224, 224))\n",
    "    \n",
    "    Returns:\n",
    "    - train_generator: Training data generator\n",
    "    - validation_generator: Validation data generator\n",
    "    - test_generator: Test data generator\n",
    "    \"\"\"\n",
    "    # Create data generators with appropriate preprocessing\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_fn\n",
    "    )\n",
    "    \n",
    "    # Validation and test generators don't need rescaling if preprocess_fn handles it\n",
    "    val_datagen = ImageDataGenerator(preprocessing_function=preprocess_fn)\n",
    "    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_fn)\n",
    "    \n",
    "    # Create generators\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    validation_generator = val_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_generator, validation_generator, test_generator\n",
    "\n",
    " # Build the model  \n",
    "def build_model(base_model_class, preprocess_fn, num_classes, input_shape=(224, 224, 3)):\n",
    "    \"\"\"Create a transfer learning model with the given base model\"\"\"\n",
    "    # Create the base model\n",
    "    base_model = base_model_class(\n",
    "        include_top=False, \n",
    "        weights='imagenet',\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    \n",
    "    # Freeze the base model\n",
    "    base_model.trainable = False\n",
    "    \n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = preprocess_fn(inputs)\n",
    "    x = base_model(x, training=False) # Keep False to freeze base model initially\n",
    "\n",
    "# Feature extraction and regularization head\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add BatchNormalization to stabilize and accelerate training\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "# Use a smaller, regularized Dense layer\n",
    "    x = Dense(256, activation='relu', # 256 is often sufficient\n",
    "                 kernel_regularizer=regularizers.l2(1e-4))(x) # Small L2 penalty\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "# Optional: Second smaller Dense layer for more capacity\n",
    "    x = Dense(128, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    x = Dropout(0.3)(x) # Slightly lower dropout\n",
    "\n",
    "# Final output layer\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Train the model \n",
    "def train_model(model_name, config, train_gen, val_gen,num_classes, epochs=50):\n",
    "    \"\"\"Train the specified model using provided generators\"\"\"\n",
    "    print(f\"\\nTraining model {model_name}.....\")\n",
    "    \n",
    "    # Build the model\n",
    "    model = build_model(\n",
    "        config['model_class'],\n",
    "        config['preprocess_fn'],\n",
    "        num_classes,\n",
    "        config['input_shape']\n",
    "    )\n",
    "    \n",
    "    # Set up callbacks\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        f'{model_name}_best_model.keras',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=12,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    tensorboard = TensorBoard(log_dir=f'logs/experiment_N1/{model_name}')\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=epochs,\n",
    "        callbacks=[checkpoint, early_stopping, reduce_lr, tensorboard],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1530fda",
   "metadata": {},
   "source": [
    " # Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf70d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_generator, model_name, class_names, save_dir):\n",
    "    \"\"\"Evaluate the model on test data and generate metrics and visualizations\"\"\"\n",
    "    # Get predictions\n",
    "    y_pred_probs = model.predict(test_generator)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    y_true = test_generator.classes\n",
    "    \n",
    "    # Calculate test accuracy\n",
    "    test_accuracy = np.mean(y_pred == y_true)\n",
    "    print(f\"Test Accuracy for {model_name}: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Classification report\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "    print(f\"Classification Report for {model_name}:\\n{report}\")\n",
    "     # ‚úÖ Save classification report\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    report_path = os.path.join(save_dir, f\"classification_report_{model_name}.txt\")\n",
    "    with open(report_path, \"w\") as f:\n",
    "        f.write(report)\n",
    "    print(f\"Classification report saved to {report_path}\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    save_path = os.path.join(save_dir, f'confusion_matrix_{model_name}.png')\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Confusion matrix saved to {save_path}\")\n",
    "    \n",
    "    # ROC Curve (for binary or multi-class classification)\n",
    "    if len(class_names) == 2:\n",
    "        # Binary classification\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_pred_probs[:, 1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'ROC Curve - {model_name}')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.tight_layout()\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        save_path = os.path.join(save_dir, f'roc_curve_{model_name}.png')\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        plt.close()\n",
    "        print(f\"ROC curve saved to {save_path}\")\n",
    "    else:\n",
    "        # Multi-class classification\n",
    "        # Binarize the output\n",
    "        y_true_bin = tf.keras.utils.to_categorical(y_true, len(class_names))\n",
    "        \n",
    "        # Compute ROC curve and ROC area for each class\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        for i in range(len(class_names)):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred_probs[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        \n",
    "        # Compute micro-average ROC curve and ROC area\n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_bin.ravel(), y_pred_probs.ravel())\n",
    "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "        \n",
    "        # Plot ROC curves\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "                 label=f'micro-average ROC curve (area = {roc_auc[\"micro\"]:.2f})',\n",
    "                 color='deeppink', linestyle=':', linewidth=4)\n",
    "        \n",
    "        colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'pink', 'brown', 'gray', 'olive'])\n",
    "        for i, color in zip(range(len(class_names)), colors):\n",
    "            plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                     label=f'ROC curve of class {class_names[i]} (area = {roc_auc[i]:.2f})')\n",
    "        \n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'ROC Curve - {model_name}')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.tight_layout()\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        save_path = os.path.join(save_dir, f'roc_curve_{model_name}.png')\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        plt.close()\n",
    "        print(f\"ROC curve saved to {save_path}\")\n",
    "    \n",
    "    return test_accuracy, report\n",
    "\n",
    "# Compare the models\n",
    "def plot_model_comparison(model_scores, save_dir):\n",
    "    \"\"\"Plot a comparison of model accuracies\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    models = list(model_scores.keys())\n",
    "    scores = list(model_scores.values())\n",
    "    \n",
    "    bars = plt.bar(models, scores, color=['blue', 'green', 'red', 'purple', 'orange'])\n",
    "    \n",
    "    # Add value labels on top of each bar\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                 f'{height:.4f}',\n",
    "                 ha='center', va='bottom')\n",
    "    \n",
    "    plt.title('Model Accuracy Comparison')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim(0, 1)  # Assuming accuracy is between 0 and 1\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    save_path = os.path.join(save_dir, 'model_comparison.png')\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Model comparison plot saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935c45d1",
   "metadata": {},
   "source": [
    "# EXPERIMENT WORKFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0107182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "source_dir = \"/content/drive/MyDrive/MRI_Orignal Data\"\n",
    "base_dir = \"/content/drive/MyDrive/my_project\"\n",
    "result_dir = \"/content/drive/MyDrive/my_project/results\"\n",
    "val_ratio = 0.10\n",
    "batch_size = 16\n",
    "num_classes = 4\n",
    "\n",
    "\n",
    "# Step 1: Visualize Original Dataset\n",
    "visualize_dataset_distribution(source_dir, result_dir, 'original')\n",
    "\n",
    "\n",
    "# Step 2: Run Dataset Pipeline\n",
    "pipeline_result = create_dataset_pipeline(source_dir, base_dir, image_size=(224, 224), val_ratio=val_ratio)\n",
    "train_dir, val_dir, test_dir = pipeline_result['train_dir'], pipeline_result['validation_dir'], pipeline_result['test_dir']\n",
    "\n",
    "\n",
    "# Step 3: Visualize Processed Dataset\n",
    "visualize_dataset_distribution(base_dir, result_dir, 'preprocessed')\n",
    "\n",
    "\n",
    "# Step 4: Train and Evaluate Models\n",
    "model_scores = {}\n",
    "for model_name, config in model_configs.items():\n",
    "    \n",
    "    print(f\"\\n{'='*50}\\nTraining {model_name}\\n{'='*50}\")\n",
    "    image_size = config['input_shape'][:2]\n",
    "    train_gen, val_gen, test_gen = setup_datagenerator(train_dir, val_dir, test_dir, config['preprocess_fn'], batch_size, image_size)\n",
    "    model, history = train_model(model_name, config, train_gen, val_gen, num_classes, epochs=100)\n",
    "    plot_training_history(history, model_name, result_dir)\n",
    "    class_names = list(train_gen.class_indices.keys())\n",
    "    test_accuracy, report = evaluate_model(model, test_gen, model_name, class_names, result_dir)\n",
    "    model_scores[model_name] = test_accuracy\n",
    "    print(report)\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "# Step 5: Compare Models\n",
    "plot_model_comparison(model_scores, result_dir)\n",
    "print(\"\\nPipeline completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157e87e8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1a74904",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
