{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ff92074-952d-43e8-87fa-26d5880cf10a",
   "metadata": {},
   "source": [
    "# **Create DataSet Pipline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9450bc-1af2-4b96-bca8-9349de1d32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_dataset_pipeline(source_dir, base_dir, image_size=(224, 224), val_ratio=0.10):\n",
    "    \"\"\"\n",
    "    Augments train & test images separately.\n",
    "    Splits only the train set into train and validation sets.\n",
    "    only final train, val, and test folders.\n",
    "    Shows progress with tqdm.\n",
    "    \"\"\"\n",
    "    print(\"Starting Data Engineering Pipeline...\")\n",
    "\n",
    "    # Final directories\n",
    "    train_dir = os.path.join(base_dir, 'train')\n",
    "    validation_dir = os.path.join(base_dir, 'validation')\n",
    "    test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "    # Remove old output \n",
    "    if os.path.exists(base_dir):\n",
    "        print(f\"Removing old base directory: {base_dir}\")\n",
    "        shutil.rmtree(base_dir)\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(validation_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    def augment_images(src_dir):\n",
    "        \"\"\"Resize + rotate + flip images and return augmented images in memory.\"\"\"\n",
    "        class_labels = [d for d in os.listdir(src_dir) if os.path.isdir(os.path.join(src_dir, d))]\n",
    "        all_files = []\n",
    "        all_labels = []\n",
    "        total_original = 0\n",
    "        total_augmented = 0\n",
    "\n",
    "        print(f\"Processing directory: {src_dir}\")\n",
    "        for class_name in class_labels:\n",
    "            src_class_dir = os.path.join(src_dir, class_name)\n",
    "            files = os.listdir(src_class_dir)\n",
    "            total_original += len(files)\n",
    "\n",
    "            for filename in tqdm(files, desc=f\"Augmenting {class_name}\", unit=\"img\"):\n",
    "                img_path = os.path.join(src_class_dir, filename)\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "\n",
    "                resized = cv2.resize(img, (image_size[1], image_size[0]))\n",
    "                rotated = cv2.rotate(resized, cv2.ROTATE_90_CLOCKWISE)\n",
    "                flipped = cv2.flip(resized, 0)\n",
    "\n",
    "                base_name, ext = os.path.splitext(filename)\n",
    "                aug_set = [\n",
    "                    (f\"{base_name}_orig{ext}\", resized),\n",
    "                    (f\"{base_name}_rot{ext}\", rotated),\n",
    "                    (f\"{base_name}_flip{ext}\", flipped)\n",
    "                ]\n",
    "\n",
    "                for new_name, new_img in aug_set:\n",
    "                    all_files.append((class_name, new_name, new_img))\n",
    "                    all_labels.append(class_name)\n",
    "                    total_augmented += 1\n",
    "\n",
    "        print(f\"Original images: {total_original}\")\n",
    "        print(f\"Augmented images (including original resized): {total_augmented}\")\n",
    "        return all_files, all_labels, class_labels\n",
    "\n",
    "    # Augment TRAIN\n",
    "    print(\"\\n=== Augmenting TRAIN set ===\")\n",
    "    train_files_aug, train_labels_aug, class_labels = augment_images(os.path.join(source_dir, 'train'))\n",
    "\n",
    "    # Split augmented train into train/validation\n",
    "    print(\"\\n=== Splitting TRAIN set into train/validation ===\")\n",
    "    train_files_list, val_files_list, train_labels_list, val_labels_list = train_test_split(\n",
    "        \n",
    "        train_files_aug, train_labels_aug,\n",
    "        test_size=val_ratio,\n",
    "        random_state=42,\n",
    "        stratify=train_labels_aug\n",
    "    )\n",
    "\n",
    "    def save_images(file_tuples, dest_dir):\n",
    "        for cls, fname, img in tqdm(file_tuples, desc=f\"Saving to {os.path.basename(dest_dir)}\", unit=\"img\"):\n",
    "            cls_dir = os.path.join(dest_dir, cls)\n",
    "            os.makedirs(cls_dir, exist_ok=True)\n",
    "            cv2.imwrite(os.path.join(cls_dir, fname), img)\n",
    "\n",
    "    # Save final TRAIN and VALIDATION sets\n",
    "    save_images(train_files_list, train_dir)\n",
    "    save_images(val_files_list, validation_dir)\n",
    "\n",
    "    # Augment TEST\n",
    "    print(\"\\n=== Augmenting TEST set ===\")\n",
    "    test_files_aug, _, _ = augment_images(os.path.join(source_dir, 'test'))\n",
    "    save_images(test_files_aug, test_dir)\n",
    "\n",
    "    # Final stats\n",
    "    print(\"\\nPipeline finished successfully.\")\n",
    "    print(f\"Final TRAIN images: {len(train_files_list)}\")\n",
    "    print(f\"Final VALIDATION images: {len(val_files_list)}\")\n",
    "    print(f\"Final TEST images: {len(test_files_aug)}\")\n",
    "\n",
    "    return {\n",
    "        'train_dir': train_dir,\n",
    "        'validation_dir': validation_dir,\n",
    "        'test_dir': test_dir,\n",
    "        'class_labels': class_labels\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41ce2b23-43d7-414b-a2f2-910f04c34443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Data Engineering Pipeline...\n",
      "Removing old base directory: F:\\Rough preprocess image\n",
      "\n",
      "=== Augmenting TRAIN set ===\n",
      "Processing directory: F:\\brain tumor classification final year project\\MRI_Orignal Data\\train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting glioma_tumor: 100%|██████████| 826/826 [00:02<00:00, 392.78img/s]\n",
      "Augmenting meningioma_tumor: 100%|██████████| 822/822 [00:03<00:00, 256.17img/s]\n",
      "Augmenting no_tumor: 100%|██████████| 395/395 [00:01<00:00, 340.57img/s]\n",
      "Augmenting pituitary_tumor: 100%|██████████| 827/827 [00:02<00:00, 283.24img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original images: 2870\n",
      "Augmented images (including original resized): 8610\n",
      "\n",
      "=== Splitting TRAIN set into train/validation ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving to train: 100%|██████████| 7749/7749 [00:12<00:00, 596.41img/s]\n",
      "Saving to validation: 100%|██████████| 861/861 [00:01<00:00, 584.88img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Augmenting TEST set ===\n",
      "Processing directory: F:\\brain tumor classification final year project\\MRI_Orignal Data\\test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting glioma_tumor: 100%|██████████| 100/100 [00:00<00:00, 230.73img/s]\n",
      "Augmenting meningioma_tumor: 100%|██████████| 115/115 [00:00<00:00, 459.45img/s]\n",
      "Augmenting no_tumor: 100%|██████████| 105/105 [00:00<00:00, 328.20img/s]\n",
      "Augmenting pituitary_tumor: 100%|██████████| 74/74 [00:00<00:00, 201.90img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original images: 394\n",
      "Augmented images (including original resized): 1182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving to test: 100%|██████████| 1182/1182 [00:01<00:00, 988.19img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pipeline finished successfully.\n",
      "Final TRAIN images: 7749\n",
      "Final VALIDATION images: 861\n",
      "Final TEST images: 1182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_dir': 'F:\\\\Rough preprocess image\\\\train',\n",
       " 'validation_dir': 'F:\\\\Rough preprocess image\\\\validation',\n",
       " 'test_dir': 'F:\\\\Rough preprocess image\\\\test',\n",
       " 'class_labels': ['glioma_tumor',\n",
       "  'meningioma_tumor',\n",
       "  'no_tumor',\n",
       "  'pituitary_tumor']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_dir, base_dir = r\"F:\\brain tumor classification final year project\\MRI_Orignal Data\",r\"F:\\Rough preprocess image\"\n",
    "create_dataset_pipeline(source_dir,base_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
